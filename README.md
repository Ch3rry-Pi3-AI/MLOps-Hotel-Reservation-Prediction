# ğŸ§© **Training Pipeline â€” MLOps Hotel Reservation Prediction**

This branch connects all previous modules â€” **data ingestion**, **data preprocessing**, and **model training** â€” into a single, orchestrated workflow.
The new **pipeline script** automates the entire process from raw data to a trained model artefact, establishing a reproducible and maintainable structure for future automation and CI/CD integration.

This stage was made easier thanks to the **modular design** of the earlier stages and the prior **notebook experimentation**, which defined the logic now formalised into pipeline components.

## ğŸ§¾ **Whatâ€™s New in This Stage**

* ğŸ†• **`pipeline/training_pipeline.py`** â€” a unified entrypoint that runs all stages sequentially:

  1. Data Ingestion
  2. Data Preprocessing
  3. Model Training
* ğŸ§  **Full automation** of the previously manual workflow â€” no need to run each module individually.
* ğŸ”§ **`config/paths_config.py`** and existing modules are reused for consistent path and configuration management.
* ğŸª¶ **Lighter README** since the logic remains unchanged â€” this stage focuses on orchestration.

## âš™ï¸ **How to Run the Full Pipeline**

After activating your virtual environment:

```bash
python pipeline/training_pipeline.py
```

This command will:

1. Ingest the raw data from your configured source
2. Preprocess and balance the dataset
3. Train and evaluate the LightGBM model
4. Save the trained model artefact to `artifacts/models/lgbm_model.pkl`
5. Log results and parameters to **MLflow**

## ğŸ—‚ï¸ **Updated Project Structure**

```
mlops-hotel-reservation-prediction/
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ lgbm_model.pkl
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml
â”‚   â”œâ”€â”€ paths_config.py
â”‚   â””â”€â”€ model_params.py
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ training_pipeline.py            # ğŸ†• Unified pipeline entrypoint
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ custom_exception.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ common_functions.py
â”œâ”€â”€ img/
â”‚   â””â”€â”€ model_training/
â”‚       â”œâ”€â”€ mlflow_experiment.png
â”‚       â””â”€â”€ mlflow_run.png
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ notebook.ipynb
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```

## ğŸš€ **Next Stage â€” Flask Application**

The next branch will focus on **creating a Flask application** to serve the trained model for real-time predictions.
This will involve:

* Loading the saved model (`artifacts/models/lgbm_model.pkl`)
* Building clean REST API endpoints
* Enabling integration with frontend interfaces or external systems

This stage marks the start of the **deployment layer** of your MLOps project â€” transitioning from model training to **model serving**.