# üß© **Source Code Directory ‚Äî `src/`**

This directory contains all **core Python modules** that define the functional backbone of the **MLOps Hotel Reservation Prediction** pipeline.
Each module performs a specific task, such as logging, data ingestion, or data preprocessing, while following consistent error handling and configuration patterns.

The `src/` folder ensures a clear separation between **code**, **configuration**, and **artifacts**, supporting modularity and ease of maintenance across all stages of the project.

## üìÅ **Folder Structure**

```
mlops-hotel-reservation-prediction/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ custom_exception.py      # Unified exception handling
‚îÇ   ‚îú‚îÄ‚îÄ data_ingestion.py        # Downloads and splits raw data from GCP
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.py    # Cleans, encodes, balances, and selects features
‚îÇ   ‚îî‚îÄ‚îÄ logger.py                # Centralised logging configuration
```

## üéØ **Overview of Modules**

### üß± `logger.py`

Centralised logging configuration for the entire project.
It automatically creates daily log files under the `logs/` directory and timestamps each message for traceability.

**Key Features**

* Configures `INFO`-level logging globally
* Stores logs in `logs/log_YYYY-MM-DD.log`
* Provides a helper function `get_logger(name)` for consistent logging across modules

**Example**

```python
from src.logger import get_logger
logger = get_logger(__name__)
logger.info("Data ingestion started.")
```

### ‚ö†Ô∏è `custom_exception.py`

Defines the `CustomException` class for descriptive, unified error handling.
Each raised exception automatically includes the **file name** and **line number** of the error, making debugging straightforward.

**Key Features**

* Wraps raw Python exceptions with contextual details
* Integrates with the global logger for consistent reporting
* Used throughout the pipeline for reliable tracebacks

**Example**

```python
try:
    result = 10 / 0
except Exception as e:
    import sys
    raise CustomException(str(e), sys)
```

### ‚òÅÔ∏è `data_ingestion.py`

Implements the `DataIngestion` class responsible for **downloading** the dataset from **Google Cloud Storage (GCS)**,
**splitting** it into training and testing subsets, and **saving** them under `artifacts/raw/`.

**Key Steps**

1. Connects to GCS via the `google-cloud-storage` client
2. Downloads the raw CSV defined in `config/config.yaml`
3. Splits the dataset into train/test based on a configured ratio
4. Logs all operations and stores files locally

**Example**

```python
from utils.common_functions import read_yaml
from config.paths_config import CONFIG_PATH
from src.data_ingestion import DataIngestion

cfg = read_yaml(CONFIG_PATH)
data_ingestion = DataIngestion(cfg)
data_ingestion.run()
```

### üßπ `data_preprocessing.py`

Encapsulates the full **data preprocessing pipeline** inside the `DataProcessor` class.
It standardises cleaning, encoding, balancing, and feature selection prior to model development.

**Main Responsibilities**

* Drop irrelevant columns and duplicates
* Apply Label Encoding for categorical variables
* Handle skewed features using `log1p`
* Balance classes via **SMOTE**
* Select top-N features using **Random Forest** importance
* Save processed data under `artifacts/processed/`

**Example**

```python
from src.data_preprocessing import DataProcessor
from config.paths_config import *

processor = DataProcessor(TRAIN_FILE_PATH, TEST_FILE_PATH, PROCESSED_DIR, CONFIG_PATH)
processor.process()
```

**Outputs**

* `processed_train.csv`
* `processed_test.csv`

## üß† **Design Principles**

* **Separation of Concerns:** Each module handles a single, well-defined task
* **Reusability:** All classes can be imported individually for debugging or testing
* **Consistency:** Unified logging, error handling, and configuration access
* **Traceability:** Each stage logs to file and uses `CustomException` for contextual errors
* **Automation-Ready:** All modules are designed for pipeline execution within CI/CD systems (e.g., Jenkins or GitHub Actions)

## ‚úÖ **Summary**

| Module                  | Responsibility                                   | Key Output                    |
| ----------------------- | ------------------------------------------------ | ----------------------------- |
| `logger.py`             | Centralised logging                              | Daily log files under `logs/` |
| `custom_exception.py`   | Unified error handling                           | Contextual exception messages |
| `data_ingestion.py`     | GCP data download and split                      | `train.csv`, `test.csv`       |
| `data_preprocessing.py` | Cleaning, encoding, balancing, feature selection | Processed CSVs                |